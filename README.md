<div align="center">

# Deep ML Practice

### _Building ML Foundations, One Problem at a Time_

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

_A curated journey through Mathematics, Machine Learning, and AI fundamentals_

[Getting Started](#-quick-start) â€¢ [Progress](#-daily-progress) â€¢ [Roadmap](#-learning-roadmap)

</div>

---

## Mission

This repository chronicles my daily expedition into the mathematical foundations of Machine Learning. Each solution is crafted with clarity, documented with purpose, and designed to build intuition from first principles.

> **Daily Commitment:** 1â€“2 problems from [Deep ML](https://www.deep-ml.com/collections)  
> **Focus Areas:** Linear Algebra â†’ Calculus â†’ Statistics â†’ ML â†’ Deep Learning

---

## Repository Structure

```
DEEP_ML/
â”‚
â”œâ”€â”€ ğŸ“ 1. Linear Algebra/
â”‚   â”œâ”€â”€ 1_Matrix-Vector-Dot-Product.py    # Foundation: Vector operations
â”‚   â”œâ”€â”€ 2_Transpose-Matrix.py              # Matrix manipulations
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“ 2. Calculus/                         # Coming soon
â”œâ”€â”€ ğŸ“ 3. Statistics/                       # Coming soon
â”œâ”€â”€ ğŸ“ 4. Machine Learning/                 # Coming soon
â”‚
â”œâ”€â”€ ğŸ venv/                                # Isolated environment
â”œâ”€â”€ ğŸ“‹ requirements.txt                     # Dependencies
â””â”€â”€ ğŸ“– README.md                            # You are here
```

---

## âš¡ Quick Start

```bash
# Clone the repository
git clone <your-repo-url>
cd DEEP_ML

# Set up virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run any solution
python "1. Linear Algebra/1_Matrix-Vector-Dot-Product.py"
```

---

## What's Inside

Each solution includes:

-   **Crystal-clear problem statements**
-   **Step-by-step implementation**
-   **Both NumPy and pure Python approaches** (when applicable)
-   **Intuitive explanations and edge case handling**
-   **Test cases and validation**

### Current Problems

<table>
<tr>
<td width="50%">

** Dot Product**

```python
# Compute A @ v with validation
# Includes dimension checking
# NumPy optimized for performance
```

</td>
<td width="50%">

** Scalar Multiplication**

```python
# Multiply every element of matrix by a scalar
# Works with int and float
# Includes validation for numeric scalar
```

</td>
</tr>
</table>

---

## ğŸ“ˆ Daily Progress

<div align="center">

| ğŸ“… Date          | ğŸ¯ Completed                                   | ğŸ“ Category    | ğŸ’­ Reflection                              |
| ---------------- | ---------------------------------------------- | -------------- | ------------------------------------------ |
| **Nov 10, 2025** | Matrix-Vector Dot Product<br/>Transpose Matrix | Linear Algebra | Mastered fundamental matrix operations     |
| **Nov 11, 2025** | Dot_product<br/>Scalar_Multiplication          | Linear Algebra | Mastered fundamental matrix multiplication |

**Current Streak:** 2 day ğŸ”¥ | **Total Problems:** 4 âœ…

</div>

---

## ğŸ—ºï¸ Learning Roadmap

```mermaid
graph LR
    A[Linear Algebra] --> B[Calculus]
    B --> C[Statistics]
    C --> D[ML Fundamentals]
    D --> E[Deep Learning]

    style A fill:#4CAF50
    style B fill:#ddd
    style C fill:#ddd
    style D fill:#ddd
    style E fill:#ddd
```

### ğŸ¯ Upcoming Topics

<details>
<summary><b>Phase 1: Linear Algebra Mastery</b></summary>

-   [ ] Matrix Determinants
-   [ ] Matrix Inverses
-   [ ] Eigenvalues & Eigenvectors
-   [ ] Singular Value Decomposition (SVD)
-   [ ] Principal Component Analysis (PCA)

</details>

<details>
<summary><b>Phase 2: Calculus Deep Dive</b></summary>

-   [ ] Gradient Descent Fundamentals
-   [ ] Partial Derivatives
-   [ ] Chain Rule Applications
-   [ ] Backpropagation Mathematics

</details>

<details>
<summary><b>Phase 3: Statistical Foundations</b></summary>

-   [ ] Probability Distributions
-   [ ] Maximum Likelihood Estimation
-   [ ] Hypothesis Testing
-   [ ] Bayesian Inference

</details>

<details>
<summary><b>Phase 4: Machine Learning Algorithms</b></summary>

-   [ ] Linear Regression from Scratch
-   [ ] Logistic Regression
-   [ ] Neural Network Basics
-   [ ] Loss Functions & Optimizers

</details>

---

## ğŸ’» Code Philosophy

> **Clean** â€¢ **Documented** â€¢ **Testable** â€¢ **Educational**

```python
# Every solution follows these principles:
def solve_problem(input_data):
    """
    Clear docstring explaining the approach

    Args:
        input_data: What goes in

    Returns:
        output: What comes out
    """
    # Step-by-step implementation
    # with explanatory comments
    pass
```

-   PEP8 compliant
-   Type hints where helpful
-   self-contained and executable
-   Optimized for learning, not just performance

---

## ğŸ¤ Connect & Contribute

<div align="center">

**Crafted with ğŸ’™ by Roushan Kumar**

[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github)](https://github.com/rkuma18)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/rk0718/)

**Learning Resources**  
[Deep ML Collections](https://www.deep-ml.com/collections) â€¢ [Python Docs](https://docs.python.org/) â€¢ [NumPy Guide](https://numpy.org/doc/)

---

_"The only way to learn mathematics is to do mathematics." â€” Paul Halmos_

**Star â­ this repo if you find it helpful!**

</div>
